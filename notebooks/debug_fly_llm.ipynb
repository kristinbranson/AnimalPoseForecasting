{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7252256c-effe-4fd7-a846-f226862a85d4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1debcedb-431d-47fe-a731-7ec1cf884216",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "\n",
    "from apf.io import read_config, get_modeltype_str\n",
    "from apf.data import load_and_filter_data, sanity_check_tspred, chunk_data\n",
    "from apf.dataset import FlyMLMDataset\n",
    "from apf.utils import get_dct_matrix, compute_npad\n",
    "from apf.features import compute_features\n",
    "from apf.plotting import initialize_debug_plots, initialize_loss_plots\n",
    "from apf.models import (\n",
    "    initialize_model, \n",
    "    initialize_loss, \n",
    "    generate_square_full_mask, \n",
    "    sanity_check_temporal_dep\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaabb5cf-1fd4-4ee1-8b4e-224ad6d91e19",
   "metadata": {},
   "source": [
    "torch.cuda.is_available()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9546f916-65cd-4f4a-bb94-34eb5baea2c8",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af74f556-61f6-4d38-9040-958801972f23",
   "metadata": {},
   "source": [
    "# configuration parameters for this model\n",
    "loadmodelfile = None\n",
    "restartmodelfile = None\n",
    "config = read_config(\"/groups/branson/home/eyjolfsdottire/code/MABe2022/config_fly_llm_multitimeglob_discrete_20230907.json\")\n",
    "\n",
    "print(f\"batch size = {config['batch_size']}\")\n",
    "\n",
    "# seed the random number generators\n",
    "np.random.seed(config['numpy_seed'])\n",
    "torch.manual_seed(config['torch_seed'])\n",
    "\n",
    "# set device (cuda/cpu)\n",
    "device = torch.device(config['device'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0251a998-51f5-435e-8ec5-51ace3a07362",
   "metadata": {},
   "source": [
    "# load raw data\n",
    "data, scale_perfly = load_and_filter_data(config['intrainfile'], config)\n",
    "# valdata, val_scale_perfly = load_and_filter_data(config['invalfile'], config)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cdf8fc-4f32-4291-ad7c-c626eb8accb9",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e13004bf-8445-44fd-8598-8387aa06f5b5",
   "metadata": {},
   "source": [
    "print(config['contextl'])\n",
    "print(config['tspred_global'])  # times to look ahead\n",
    "\n",
    "print(data.keys())\n",
    "print(data['X'].shape)  # n_kpts x n_dim x n_frames x n_flies\n",
    "print(data['y'].shape)  # n_categories x n_frames x n_flies\n",
    "print(data['ids'].max())  # 907: why is this so high? Is it because it adds a + i*12 for each new video? Yep that's it\n",
    "\n",
    "print(scale_perfly.shape)  # len(scalenames) x max_n_flies\n",
    "\n",
    "from apf.config import scalenames\n",
    "from apf.features import compute_scale_perfly\n",
    "scalenames\n",
    "# compute_scale_perfly??\n",
    "# compute_npad??\n",
    "# get_dct_matrix??\n",
    "# chunk_data??"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "408a08a3-1be5-4675-8dd2-12efa7ca4d6d",
   "metadata": {},
   "source": [
    "## Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad0d6651-81a8-4f20-a191-30efc311b11e",
   "metadata": {},
   "source": [
    "# compute_features??"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b17072-a69f-4263-bb9d-1d3c634bd571",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# if using discrete cosine transform, create dct matrix\n",
    "# this didn't seem to work well, so probably won't use in the future\n",
    "if config['dct_tau'] is not None and config['dct_tau'] > 0:\n",
    "    dct_m, idct_m = get_dct_matrix(config['dct_tau'])\n",
    "    # this gives the maximum of \n",
    "    #   a) max number of frames to lookahead or \n",
    "    #   b) dct_tau (number of timepoints for cosine transform)\n",
    "else:\n",
    "    dct_m = None\n",
    "    idct_m = None\n",
    "\n",
    "# how much to pad outputs by -- depends on how many frames into the future we will predict\n",
    "npad = compute_npad(config['tspred_global'], dct_m)\n",
    "chunk_data_params = {'npad': npad}\n",
    "\n",
    "compute_feature_params = {\n",
    " \"simplify_out\": config['simplify_out'],\n",
    " \"simplify_in\": config['simplify_in'],\n",
    " \"dct_m\": dct_m,\n",
    " \"tspred_global\": config['tspred_global'],\n",
    " \"compute_pose_vel\": config['compute_pose_vel'],\n",
    " \"discreteidx\": config['discreteidx'],\n",
    "}\n",
    "\n",
    "# function for computing features\n",
    "reparamfun = lambda x, id, flynum, **kwargs: compute_features(\n",
    "    x, id, flynum, scale_perfly, outtype=np.float32, **compute_feature_params, **kwargs)\n",
    "\n",
    "val_reparamfun = lambda x, id, flynum, **kwargs: compute_features(\n",
    "    x, id, flynum, val_scale_perfly, outtype=np.float32, **compute_feature_params, **kwargs)\n",
    "\n",
    "# sanity check on computing features when predicting many frames into the future\n",
    "sanity_check_tspred(\n",
    "    data, \n",
    "    compute_feature_params,\n",
    "    npad,\n",
    "    scale_perfly,\n",
    "    contextl=config['contextl'],\n",
    "    t0=510,\n",
    "    flynum=0\n",
    ")\n",
    "\n",
    "# chunk the data if we didn't load the pre-chunked cache file\n",
    "print('Chunking training data...')\n",
    "X = chunk_data(data, config['contextl'], reparamfun, **chunk_data_params)\n",
    "# print('Chunking val data...')\n",
    "# valX = chunk_data(valdata, config['contextl'], val_reparamfun, **chunk_data_params)\n",
    "print('Done.')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28152075-bcfa-4207-acce-cacf7fc98fe1",
   "metadata": {},
   "source": [
    "print(len(X))  # batches\n",
    "print(X[0].keys())\n",
    "print(X[0]['input'].shape)  # contextl x n_features ?\n",
    "print(X[0]['labels'].shape)  # contextl x n_pred_features ?\n",
    "print(X[0]['scale'].shape)  # len(scalenames)\n",
    "X[0]['metadata']"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e5eb2c2d-efa2-4fa6-aaa4-6e722f3138d6",
   "metadata": {},
   "source": [
    "## Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "931e896e-1a1b-4aa7-82a4-22537fbcbe06",
   "metadata": {},
   "source": [
    "from importlib import reload\n",
    "from apf import dataset as apfdataset\n",
    "reload(apfdataset)\n",
    "\n",
    "config['input_noise_sigma']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c40040a4-67c2-49d7-96bf-2cd7ce98b3b9",
   "metadata": {},
   "source": [
    "dataset_params = {\n",
    "    'max_mask_length': config['max_mask_length'],\n",
    "    'pmask': config['pmask'],\n",
    "    'masktype': config['masktype'],\n",
    "    'simplify_out': config['simplify_out'],\n",
    "    'pdropout_past': config['pdropout_past'],\n",
    "    'input_labels': config['input_labels'],\n",
    "    'dozscore': True,\n",
    "    'discreteidx': config['discreteidx'],\n",
    "    'discretize_nbins': config['discretize_nbins'],\n",
    "    'discretize_epsilon': config['discretize_epsilon'],\n",
    "    'flatten_labels': config['flatten_labels'],\n",
    "    'flatten_obs_idx': config['flatten_obs_idx'],\n",
    "    'flatten_do_separate_inputs': config['flatten_do_separate_inputs'],\n",
    "    'p_add_input_noise': config['p_add_input_noise'],\n",
    "    'dct_ms': (dct_m,idct_m),\n",
    "    'tspred_global': config['tspred_global'],\n",
    "    'discrete_tspred': config['discrete_tspred'],\n",
    "    'compute_pose_vel': config['compute_pose_vel'],\n",
    "}\n",
    "train_dataset_params = {\n",
    "    'input_noise_sigma': config['input_noise_sigma'],\n",
    "}\n",
    "\n",
    "print('Creating training data set...')\n",
    "train_dataset = FlyMLMDataset(X,**train_dataset_params,**dataset_params)\n",
    "print('Done.')\n",
    "\n",
    "# zscore and discretize parameters for validation data set based on train data\n",
    "# we will continue to use these each time we rechunk the data\n",
    "dataset_params['zscore_params'] = train_dataset.get_zscore_params()\n",
    "dataset_params['discretize_params'] = train_dataset.get_discretize_params()\n",
    "\n",
    "# print('Creating validation data set...')\n",
    "# val_dataset = FlyMLMDataset(valX,**dataset_params)\n",
    "# print('Done.')\n",
    "\n",
    "# get properties of examples from the first training example\n",
    "example = train_dataset[0]\n",
    "d_input = example['input'].shape[-1]\n",
    "d_output = train_dataset.d_output\n",
    "outnames = train_dataset.get_outnames()\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                batch_size=config['batch_size'],\n",
    "                                                shuffle=True,\n",
    "                                                pin_memory=True,\n",
    "                                                )\n",
    "ntrain = len(train_dataloader)\n",
    "\n",
    "# val_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
    "#                                               batch_size=config['batch_size'],\n",
    "#                                               shuffle=False,\n",
    "#                                               pin_memory=True,\n",
    "#                                               )\n",
    "# nval = len(val_dataloader)\n",
    "\n",
    "example = next(iter(train_dataloader))\n",
    "sz = example['input'].shape\n",
    "print(f'batch input shape = {sz}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22da1278-7c45-4599-b113-fafeb271bfba",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b450946-c564-4ef7-a0c5-fd7f84faa4b4",
   "metadata": {},
   "source": [
    "# X has dim 211, but train data has dim 241, where does the extra 30 come from?\n",
    "print(len(train_dataset))  # same as x\n",
    "print(ntrain)\n",
    "print(len(X) / config['batch_size'])\n",
    "print(type(train_dataset))  # torch.utils.data.Dataset\n",
    "print(d_input, d_output)\n",
    "# train_dataset.data[0].shape\n",
    "# outnames\n",
    "\n",
    "print(train_dataset.dfeat)\n",
    "print(train_dataset.nextframeidx)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d30bd6a-c7c3-4f0d-b885-354951c0e9c7",
   "metadata": {},
   "source": [
    "from importlib import reload\n",
    "from apf import plotting\n",
    "reload(plotting)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4519b8db-1ce3-4869-b5a4-ee71d57e65e6",
   "metadata": {},
   "source": [
    "# set up debug plots\n",
    "plt.ion()\n",
    "debug_params = {}\n",
    "# if contextl is long, still just look at samples from the first 64 frames\n",
    "if config['contextl'] > 64:\n",
    "    debug_params['tsplot'] = np.round(np.linspace(0,64,5)).astype(int)\n",
    "    debug_params['traj_nsamplesplot'] = 1\n",
    "hdebug = {}\n",
    "hdebug['train'] = plotting.initialize_debug_plots(train_dataset, train_dataloader, data,name='Train', **debug_params)\n",
    "# hdebug['val'] = initialize_debug_plots(val_dataset, val_dataloader, valdata, name='Val', **debug_params)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "31adc2b4-6105-43d4-b222-3bc48d9753d8",
   "metadata": {},
   "source": [
    "## Set up model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aca76dd-66d3-4cd2-93cc-515593ad7a2e",
   "metadata": {},
   "source": [
    "# create the model\n",
    "model, criterion = initialize_model(d_input, d_output, config, train_dataset, device)\n",
    "\n",
    "# optimizer\n",
    "num_training_steps = config['num_train_epochs'] * ntrain\n",
    "optimizer = transformers.optimization.AdamW(model.parameters(), **config['optimizer_args'])\n",
    "lr_scheduler = transformers.get_scheduler('linear', optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "\n",
    "# initialize structure to keep track of loss\n",
    "loss_epoch = initialize_loss(train_dataset, config)\n",
    "last_val_loss = None\n",
    "\n",
    "hloss = initialize_loss_plots(loss_epoch)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d57db8a-c30d-44e0-a8e2-df5c17ad9fdd",
   "metadata": {},
   "source": [
    "print(type(model))  # torch.nn.Module\n",
    "criterion??\n",
    "\n",
    "# lossfcn_discrete = torch.nn.CrossEntropyLoss()\n",
    "# lossfcn_continuous = torch.nn.L1Loss()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6975e664-6806-4bbf-acee-095f8f2d8ecc",
   "metadata": {},
   "source": [
    "## Create attention mask \n",
    "(e.g. mask out t+1, .. t+n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "822fdb0b-c9d5-4bbe-bf01-bcf1c76ec6d4",
   "metadata": {},
   "source": [
    "# create attention mask\n",
    "contextl = example['input'].shape[1]\n",
    "if config['modeltype'] == 'mlm':\n",
    "    train_src_mask = generate_square_full_mask(contextl).to(device)\n",
    "    is_causal = False\n",
    "elif config['modeltype'] == 'clm':\n",
    "    train_src_mask = torch.nn.Transformer.generate_square_subsequent_mask(contextl, device=device)\n",
    "    is_causal = True\n",
    "    #train_src_mask = generate_square_subsequent_mask(contextl).to(device)\n",
    "else:\n",
    "    raise\n",
    "\n",
    "# sanity check on temporal dependences\n",
    "sanity_check_temporal_dep(train_dataloader, device, train_src_mask, is_causal, model, tmess=300)\n",
    "\n",
    "modeltype_str = get_modeltype_str(config, train_dataset)\n",
    "if ('model_nickname' in config) and (config['model_nickname'] is not None):\n",
    "    modeltype_str = config['model_nickname']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "171d2973-a5f7-41db-89e6-7899ad838b4f",
   "metadata": {},
   "source": [
    "m = train_src_mask.cpu()\n",
    "plt.figure()\n",
    "plt.imshow(m)\n",
    "plt.show()\n",
    "# -Inf at future timesteps, otherwise 0"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9ecbdd1e-e26b-478c-9002-ce9c1f658dc5",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0636c52-3e3c-4a38-994b-246e277dd305",
   "metadata": {},
   "source": [
    "import tqdm\n",
    "import datetime\n",
    "from apf.models import criterion_wrapper\n",
    "from apf.plotting import update_debug_plots\n",
    "\n",
    "# train\n",
    "epoch = 0\n",
    "progress_bar = tqdm.tqdm(range(num_training_steps))\n",
    "\n",
    "savetime = datetime.datetime.now()\n",
    "savetime = savetime.strftime('%Y%m%dT%H%M%S')\n",
    "ntimepoints_per_batch = train_dataset.ntimepoints\n",
    "# valexample = next(iter(val_dataloader))\n",
    "\n",
    "for epoch in range(epoch, config['num_train_epochs']):\n",
    "      \n",
    "    model.train()\n",
    "    tr_loss = torch.tensor(0.0).to(device)\n",
    "    if train_dataset.discretize:\n",
    "        tr_loss_discrete = torch.tensor(0.0).to(device)\n",
    "        tr_loss_continuous = torch.tensor(0.0).to(device)\n",
    "    \n",
    "    nmask_train = 0\n",
    "    for step, example in enumerate(train_dataloader):\n",
    "    \n",
    "        pred = model(example['input'].to(device=device), mask=train_src_mask, is_causal=is_causal)\n",
    "        loss, loss_discrete, loss_continuous = criterion_wrapper(example, pred, criterion, train_dataset, config)\n",
    "          \n",
    "        loss.backward()\n",
    "        \n",
    "        # how many timepoints are in this batch for normalization\n",
    "        if config['modeltype'] == 'mlm':\n",
    "            nmask_train += torch.count_nonzero(example['mask'])\n",
    "        else:\n",
    "            nmask_train += example['input'].shape[0]*ntimepoints_per_batch \n",
    "    \n",
    "        if step % config['niterplot'] == 0:\n",
    "          \n",
    "            with torch.no_grad():\n",
    "                trainpred = model.output(example['input'].to(device=device),mask=train_src_mask,is_causal=is_causal)\n",
    "                # valpred = model.output(valexample['input'].to(device=device),mask=train_src_mask,is_causal=is_causal)\n",
    "            update_debug_plots(hdebug['train'],config,model,train_dataset,example,trainpred,name='Train',criterion=criterion,**debug_params)\n",
    "            # update_debug_plots(hdebug['val'],config,model,val_dataset,valexample,valpred,name='Val',criterion=criterion,**debug_params)\n",
    "            plt.show()\n",
    "            plt.pause(.1)\n",
    "    \n",
    "        tr_loss_step = loss.detach()\n",
    "        tr_loss += tr_loss_step\n",
    "        if train_dataset.discretize:\n",
    "            tr_loss_discrete += loss_discrete.detach()\n",
    "            tr_loss_continuous += loss_continuous.detach()\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),config['max_grad_norm'])\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # update progress bar\n",
    "        stat = {'train loss': tr_loss.item()/nmask_train,'last val loss': last_val_loss,'epoch': epoch}\n",
    "        if train_dataset.discretize:\n",
    "            stat['train loss discrete'] = tr_loss_discrete.item()/nmask_train\n",
    "            stat['train loss continuous'] = tr_loss_continuous.item()/nmask_train\n",
    "        progress_bar.set_postfix(stat)\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "        # end of iteration loop\n",
    "\n",
    "        break ## DEBUG\n",
    "\n",
    "    break ## DEBUG\n",
    "    \n",
    "    # training epoch complete\n",
    "    loss_epoch['train'][epoch] = tr_loss.item() / nmask_train\n",
    "    if train_dataset.discretize:\n",
    "        loss_epoch['train_discrete'][epoch] = tr_loss_discrete.item() / nmask_train\n",
    "        loss_epoch['train_continuous'][epoch] = tr_loss_continuous.item() / nmask_train\n",
    "    \"\"\"\n",
    "    # compute validation loss after this epoch\n",
    "    if val_dataset.discretize:\n",
    "         loss_epoch['val'][epoch],loss_epoch['val_discrete'][epoch],loss_epoch['val_continuous'][epoch] = \\\n",
    "           compute_loss(model,val_dataloader,val_dataset,device,train_src_mask,criterion,config)\n",
    "    else:\n",
    "        loss_epoch['val'][epoch] = \\\n",
    "          compute_loss(model,val_dataloader,val_dataset,device,train_src_mask,criterion,config)\n",
    "    last_val_loss = loss_epoch['val'][epoch].item()\n",
    "    \"\"\"\n",
    "    update_loss_plots(hloss,loss_epoch)\n",
    "    plt.show()\n",
    "    plt.pause(.1)\n",
    "    \n",
    "    # rechunk the training data\n",
    "    if np.mod(epoch+1,config['epochs_rechunk']) == 0:\n",
    "        print(f'Rechunking data after epoch {epoch}')\n",
    "        X = chunk_data(data,config['contextl'],reparamfun,**chunk_data_params)\n",
    "      \n",
    "        train_dataset = FlyMLMDataset(X,**train_dataset_params,**dataset_params)\n",
    "        print('New training data set created')\n",
    "    \n",
    "    if (epoch+1)%config['save_epoch'] == 0:\n",
    "        savefile = os.path.join(config['savedir'],f\"fly{modeltype_str}_epoch{epoch+1}_{savetime}.pth\")\n",
    "        print(f'Saving to file {savefile}')\n",
    "        save_model(savefile,model,lr_optimizer=optimizer,scheduler=lr_scheduler,loss=loss_epoch,config=config)\n",
    "\n",
    "print('Done training')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45ab659f-4e7c-48e7-80a4-bafd8dadaf1f",
   "metadata": {},
   "source": [
    "model.pos_encoder"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5011a-368c-4a03-9eb1-30a994335506",
   "metadata": {},
   "source": [
    "  model.eval()\n",
    "\n",
    "  # compute predictions and labels for all validation data using default masking\n",
    "  all_pred,all_labels,all_mask,all_pred_discrete,all_labels_discrete = predict_all(val_dataloader,val_dataset,model,config,train_src_mask)\n",
    "\n",
    "  # plot comparison between predictions and labels on validation data\n",
    "  predv = stack_batch_list(all_pred)\n",
    "  labelsv = stack_batch_list(all_labels)\n",
    "  maskv = stack_batch_list(all_mask)\n",
    "  pred_discretev = stack_batch_list(all_pred_discrete)\n",
    "  labels_discretev = stack_batch_list(all_labels_discrete)\n",
    "  \n",
    "  fig,ax = debug_plot_global_histograms(predv,labelsv,train_dataset,nbins=25,subsample=1,compare='pred')\n",
    "  \n",
    "  if train_dataset.dct_m is not None:\n",
    "    debug_plot_dct_relative_error(predv,labelsv,train_dataset)\n",
    "  if train_dataset.ntspred_global > 1:\n",
    "    debug_plot_global_error(predv,labelsv,pred_discretev,labels_discretev,train_dataset)\n",
    "\n",
    "  # crop to nplot for plotting\n",
    "  nplot = 8000 #min(len(all_labels),8000//config['batch_size']//config['contextl']+1)\n",
    "  predv = predv[:nplot,:]\n",
    "  labelsv = labelsv[:nplot,:]\n",
    "  if len(maskv) > 0:\n",
    "    maskv = maskv[:nplot,:]\n",
    "  pred_discretev = pred_discretev[:nplot,:]\n",
    "  labels_discretev = labels_discretev[:nplot,:]\n",
    "  \n",
    "  if maskv is not None and len(maskv) > 0:\n",
    "    maskidx = torch.nonzero(maskv)[:,0]\n",
    "  else:\n",
    "    maskidx = None\n",
    "  \n",
    "  ntspred_plot = np.minimum(4,train_dataset.ntspred_global)\n",
    "  featidxplot = select_featidx_plot(train_dataset,ntspred_plot)\n",
    "  naxc = np.maximum(1,int(np.round(len(featidxplot)/nfeatures)))\n",
    "  fig,ax = debug_plot_predictions_vs_labels(predv,labelsv,pred_discretev,labels_discretev,outnames=outnames,maskidx=maskidx,naxc=naxc,featidxplot=featidxplot,dataset=val_dataset)\n",
    "  if train_dataset.ntspred_global > 1:\n",
    "    featidxplot = select_featidx_plot(train_dataset,ntspred_plot=train_dataset.ntspred_global,ntsplot_relative=0)\n",
    "    naxc = np.maximum(1,int(np.round(len(featidxplot)/nfeatures)))\n",
    "    fig,ax = debug_plot_predictions_vs_labels(predv,labelsv,pred_discretev,labels_discretev,outnames=outnames,maskidx=maskidx,naxc=naxc,featidxplot=featidxplot,dataset=val_dataset)\n",
    "  \n",
    "  if train_dataset.ntspred_global > 1:\n",
    "    featidxplot = train_dataset.ravel_label_index([(featglobal[0],t) for t in train_dataset.tspred_global])\n",
    "    fig,ax = debug_plot_predictions_vs_labels(predv,labelsv,pred_discretev,labels_discretev,outnames=outnames,maskidx=maskidx,featidxplot=featidxplot,dataset=val_dataset)\n",
    "\n",
    "  if train_dataset.dct_tau > 0:\n",
    "    fstrs = ['left_middle_leg_tip_angle','left_front_leg_tip_angle','left_wing_angle']\n",
    "    fs = [mabe.posenames.index(x) for x in fstrs]\n",
    "    featidxplot = train_dataset.ravel_label_index([(f,i+1) for i in range(train_dataset.dct_tau+1) for f in fs])\n",
    "    fig,ax = debug_plot_predictions_vs_labels(predv,labelsv,pred_discretev,labels_discretev,outnames=outnames,maskidx=maskidx,featidxplot=featidxplot,dataset=val_dataset,naxc=len(fs))\n",
    "\n",
    "    predrelative_dct = train_dataset.get_relative_movement_dct(predv.numpy())\n",
    "    labelsrelative_dct = train_dataset.get_relative_movement_dct(labelsv.numpy())\n",
    "    fsdct = [np.array(mabe.posenames)[featrelative].tolist().index(x) for x in fstrs]\n",
    "    predrelative_dct = predrelative_dct[:,:,fsdct].astype(train_dataset.dtype)\n",
    "    labelsrelative_dct = labelsrelative_dct[:,:,fsdct].astype(train_dataset.dtype)\n",
    "    outnamescurr = [f'{f}_dt{i+1}' for i in range(train_dataset.dct_tau) for f in fstrs]\n",
    "    fig,ax = debug_plot_predictions_vs_labels(torch.as_tensor(predrelative_dct.reshape((-1,train_dataset.dct_tau*len(fsdct)))),\n",
    "                                              torch.as_tensor(labelsrelative_dct.reshape((-1,train_dataset.dct_tau*len(fsdct)))),\n",
    "                                              outnames=outnamescurr,maskidx=maskidx,naxc=len(fstrs))\n",
    "\n",
    "\n",
    "  # generate an animation of open loop prediction\n",
    "  tpred = 2000 + config['contextl']\n",
    "\n",
    "  # all frames must have real data\n",
    "  \n",
    "  burnin = config['contextl']-1\n",
    "  contextlpad = burnin + 1\n",
    "  allisdata = interval_all(valdata['isdata'],contextlpad)\n",
    "  isnotsplit = interval_all(valdata['isstart']==False,tpred)[1:,...]\n",
    "  canstart = np.logical_and(allisdata[:isnotsplit.shape[0],:],isnotsplit)\n",
    "  flynum = 2\n",
    "  t0 = np.nonzero(canstart[:,flynum])[0][40000]    \n",
    "  # flynum = 2\n",
    "  # t0 = np.nonzero(canstart[:,flynum])[0][0]\n",
    "  fliespred = np.array([flynum,])\n",
    "\n",
    "  randstate_np = np.random.get_state()\n",
    "  randstate_torch = torch.random.get_rng_state()\n",
    "\n",
    "  nsamplesfuture = 32  \n",
    "  \n",
    "  # reseed numpy random number generator with randstate_np\n",
    "  np.random.set_state(randstate_np)\n",
    "  # reseed torch random number generator with randstate_torch\n",
    "  torch.random.set_rng_state(randstate_torch)\n",
    "  ani = animate_predict_open_loop(model,val_dataset,valdata,val_scale_perfly,config,fliespred,t0,tpred,debug=False,\n",
    "                                  plotattnweights=False,plotfuture=train_dataset.ntspred_global>1,nsamplesfuture=nsamplesfuture)\n",
    "\n",
    "  vidtime = datetime.datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "  savevidfile = os.path.join(config['savedir'],f\"samplevideo_{modeltype_str}_{savetime}_{vidtime}.gif\")\n",
    "\n",
    "  print('Saving animation to file %s...'%savevidfile)\n",
    "  writer = animation.PillowWriter(fps=30)\n",
    "  ani.save(savevidfile,writer=writer)\n",
    "  print('Finished writing.')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cb1cc8-7dd3-45c0-9277-3cb2f9fa7755",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9effc9e-04d3-4366-a6fb-c4632a7e9f28",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c934a-a13a-41e5-8608-e1d02d8fce9f",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
